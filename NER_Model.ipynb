{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-26T13:38:22.020718Z",
     "start_time": "2024-05-26T13:38:22.004051Z"
    }
   },
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, Trainer"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T13:38:23.261306Z",
     "start_time": "2024-05-26T13:38:23.098488Z"
    }
   },
   "cell_type": "code",
   "source": [
    "resume_text = \"\"\"\n",
    "Braulio Jose Cespedes Acosta | Toronto, ON | (437) 733-7952 | brauliojose.cespedesacosta@georgebrown.ca|\n",
    "https://github.com/Murphyx2 | https://www.linkedin.com/in/braulio-cespedes-acosta/\n",
    "Objective:\n",
    "Seeking Software Development Co-op at Loblaw, leveraging expertise from the Applied A.I. Solutions\n",
    "Development Postgraduate Co-op program. Eager to apply skills in developing AI and data analytics\n",
    "solutions, while fostering collaboration within the team.\n",
    "Highlights of Qualifications:\n",
    "• Strong knowledge and experience in Java programming language, developing backend and middleware\n",
    "systems.\n",
    "• Moderate Knowledge of Python, training and developing machine learning models.\n",
    "• Demonstrated ability to refine technical specifications for efficient project execution.\n",
    "• Proven track record in planning, requirements gathering, and risk management for successful projects.\n",
    "• Exceptional communication skills, translating user requirements into technical requirements for\n",
    "collaboration across teams and developing software.\n",
    "• Moderate skill at data visualization with Tableau software.\n",
    "Technical Skill:\n",
    "• Databases Systems: Oracle, MS SQL server, MySQL.\n",
    "• Control Version: Git\n",
    "• Software Documentation: Microsoft Office (Excel, Word, PowerPoint)\n",
    "• Testing: Java Mockito, Python Pytest\n",
    "• Programming languages: Java, Python\n",
    "Education:\n",
    "Applied A.I. Solutions Development Postgraduate Jan 2024 – Dec 2024\n",
    "George Brown College, Toronto, ON\n",
    "• Collaborate with cross-disciplinary teams developing and understanding machine learning models in\n",
    "order to perform the tasks at hand and complete the objectives of the course.\n",
    "• Lead cross-disciplinary teams with the purpose of achieving the task and objectives at hand, bringing\n",
    "their best potential in order to achieve the best score.\n",
    "• Moderate knowledge of Tableau visualization tools, for the visualization and data presentation.\n",
    "• Basic knowledge of the different big data technologies, such as Hadoop, Spark, Hive and Apache Pig as\n",
    "well as their deployment in a cloud environment in MS Azure.\n",
    "Software Engineer 2014 - 2019\n",
    "Universidad Pro Educación y Cultura (APEC)\n",
    "• Knowledge and the skills to analyze, design, develop, test, and implement software with the highest\n",
    "standards and best practices on the market, all of these to fulfill users' needs on time.\n",
    "• Collaborated with teams in order to plan, design, and develop software for different purposes in Java,\n",
    "Python, and C#.\n",
    "Mechatronics Technologist 2010 - 2013\n",
    "Las Americas Institute of Technology (ITLA)\n",
    "• As a Mechatronics Technologist, we dominate the automation of manufacturing processes by integrating\n",
    "mechanical, electrical, electronic, and software components used for the control.\n",
    "• Capable of designing and manufacturing electronic prototypes and devices.\n",
    "Braulio Jose Cespedes Acosta | Toronto, ON | (437) 733-7952 | brauliojose.cespedesacosta@georgebrown.ca|\n",
    "https://github.com/Murphyx2 | https://www.linkedin.com/in/braulio-cespedes-acosta/\n",
    "Professional Experience:\n",
    "Mid Software Developer Feb 2022 – Feb 2024\n",
    "FullstackLabs, Santo Domingo DR - Remote\n",
    "• Analyze, design, develop and test software in order to create new features and solve problems in the\n",
    "organization, in order to meet users' needs and expectations.\n",
    "• Provide support to users and colleagues for problem-solving situations, testing phase for new software\n",
    "features, issues in the production environment, and consultation for the development and implementation of\n",
    "new features and other requests related to the software development cycle.\n",
    "• Development of SQL scripts to fulfill the software needs or for information requests.\n",
    "• Translate user requests and requirements into tasks and technical requirements in order to develop features\n",
    "that fulfill organizations' needs.\n",
    "Engineer IV (Software Engineer) Jun 2018 – Feb 2022\n",
    "Claro Dominicana, Santo Domingo DR\n",
    "• Analyze, design, develop and test software in order to create new features and solve problems in the\n",
    "organization, in order to meet users' needs and expectations.\n",
    "• Development of SQL scripts, procedures, and views to fulfill the software needs or for information requests.\n",
    "• Provided mentorship and guidance for new or old colleagues related to software development.\n",
    "• Provided guidance and software tools to QA and support production teams in order to fulfill the\n",
    "organization's needs and goals.\n",
    "• Provide support for the integration and implementation of third-party software into the organization.\n",
    "• Lead a small development team in order to maintain and implement new features for designated\n",
    "applications.\n",
    "• Planning and management of software delivery from the dev environment into the production environment.\n",
    "Software Engineer Apr 2016 – Jun 2018\n",
    "NewTech.srl, Santo Domingo DR\n",
    "• Analyze, design, develop and test software in order to create new features and solve problems in the\n",
    "organization, in order to meet users' needs and expectations.\n",
    "• Provide support to users and colleagues for problem-solving situations, testing phase for new software\n",
    "features, issues in the production environment, and consultation for the development and implementation of\n",
    "new features and other requests related to the software development cycle.\n",
    "• Development of SQL scripts to fulfill the software needs or for information requests.\n",
    "• Planning and management of software delivery from the dev environment into the production environment.\n",
    "Interests:\n",
    "• Stock Market, Real estate, Economics, Assembling scale models, Books, Playing Video games, World\n",
    "History, Military equipment, strategists and Science and Pixel Art.\n",
    "\"\"\"\n",
    "\n",
    "entities = [\n",
    "    (336, 340, \"SKILL\"),     # Java\n",
    "    (374, 380, \"SKILL\"),     # Python\n",
    "    (444, 467, \"SKILL\"),     # machine learning\n",
    "    (587, 606, \"SKILL\"),     # communication skills\n",
    "    (660, 680, \"SKILL\"),     # data visualization\n",
    "    (700, 706, \"SKILL\"),     # Oracle\n",
    "    (708, 720, \"SKILL\"),     # MS SQL server\n",
    "    (722, 728, \"SKILL\"),     # MySQL\n",
    "    (745, 748, \"SKILL\"),     # Git\n",
    "    (770, 795, \"SKILL\"),     # Microsoft Office\n",
    "    (808, 821, \"SKILL\"),     # Java Mockito\n",
    "    (823, 835, \"SKILL\"),     # Python Pytest\n",
    "    (854, 858, \"SKILL\"),     # Java\n",
    "    (860, 866, \"SKILL\"),     # Python\n",
    "    (1220, 1226, \"SKILL\"),   # Hadoop\n",
    "    (1228, 1233, \"SKILL\"),   # Spark\n",
    "    (1235, 1239, \"SKILL\"),   # Hive\n",
    "    (1244, 1254, \"SKILL\"),   # Apache Pig\n",
    "    (1274, 1282, \"SKILL\"),   # MS Azure\n",
    "    (1476, 1479, \"SKILL\"),   # Java\n",
    "    (1481, 1487, \"SKILL\"),   # Python\n",
    "    (1492, 1494, \"SKILL\")    # C#\n",
    "]\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
   ],
   "id": "7faf421b4543d06a",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T13:38:23.882363Z",
     "start_time": "2024-05-26T13:38:23.873846Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def tokenize_and_align_labels(text, entities, tokenizer):\n",
    "    tokens = tokenizer(text, return_offsets_mapping=True, truncation=True)\n",
    "    labels = [\"0\"] * len(tokens[\"input_ids\"])\n",
    "    \n",
    "    for start, end, label in entities:\n",
    "        for idx, (token_start, token_end) in enumerate(tokens[\"offset_mapping\"]):\n",
    "            if token_start >= start and token_end <=end:\n",
    "                labels[idx] = label\n",
    "    \n",
    "    return tokens, labels"
   ],
   "id": "a86a2106a5336818",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T13:38:24.378646Z",
     "start_time": "2024-05-26T13:38:24.358702Z"
    }
   },
   "cell_type": "code",
   "source": "tokens, labels = tokenize_and_align_labels(resume_text, entities, tokenizer)",
   "id": "4aef5b7f229a69ee",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T13:38:24.905265Z",
     "start_time": "2024-05-26T13:38:24.886404Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ResumeDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ],
   "id": "c289c6ff5477efb4",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T13:38:25.402310Z",
     "start_time": "2024-05-26T13:38:25.379263Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Creating Dataset\n",
    "encodings, labels = tokenize_and_align_labels(resume_text, entities, tokenizer)\n",
    "dataset = ResumeDataset(encodings, [labels])"
   ],
   "id": "46c37729f684ea90",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Training the model",
   "id": "f71b072ccb8f1072"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T13:39:03.055951Z",
     "start_time": "2024-05-26T13:39:02.628338Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(\"bert-base-cased\", num_labels=len(labels))\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,    \n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    "    eval_dataset=dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ],
   "id": "68f106abfa430fd7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "TrainingArguments.__init__() got an unexpected keyword argument 'bias'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[19], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m model \u001B[38;5;241m=\u001B[39m AutoModelForTokenClassification\u001B[38;5;241m.\u001B[39mfrom_pretrained(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbert-base-cased\u001B[39m\u001B[38;5;124m\"\u001B[39m, num_labels\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlen\u001B[39m(labels))\n\u001B[1;32m----> 3\u001B[0m training_args \u001B[38;5;241m=\u001B[39m \u001B[43mTrainingArguments\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m./results\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43mevaluation_strategy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mepoch\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlearning_rate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2e-5\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[43mper_device_train_batch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m16\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[43m    \u001B[49m\u001B[43mper_device_eval_batch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m16\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_train_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     10\u001B[0m \u001B[43m    \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     11\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     12\u001B[0m \u001B[43m    \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.2\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     13\u001B[0m \u001B[43m    \u001B[49m\n\u001B[0;32m     14\u001B[0m \u001B[43m)\u001B[49m\n\u001B[0;32m     16\u001B[0m trainer \u001B[38;5;241m=\u001B[39m Trainer(\n\u001B[0;32m     17\u001B[0m     model\u001B[38;5;241m=\u001B[39mmodel,\n\u001B[0;32m     18\u001B[0m     args\u001B[38;5;241m=\u001B[39mtraining_args,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     21\u001B[0m     tokenizer\u001B[38;5;241m=\u001B[39mtokenizer,\n\u001B[0;32m     22\u001B[0m )\n\u001B[0;32m     24\u001B[0m trainer\u001B[38;5;241m.\u001B[39mtrain()\n",
      "\u001B[1;31mTypeError\u001B[0m: TrainingArguments.__init__() got an unexpected keyword argument 'bias'"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T13:38:30.057409Z",
     "start_time": "2024-05-26T13:38:30.028838Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Evaluate the model\n",
    "trainer.evaluate()\n",
    "\n",
    "# Save the model\n",
    "trainer.save_model(\"./ner_model\")\n",
    "tokenizer.save_pretrained(\"./ner_model\")"
   ],
   "id": "3eccee7378526bd2",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[18], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Evaluate the model\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241m.\u001B[39mevaluate()\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# Save the model\u001B[39;00m\n\u001B[0;32m      5\u001B[0m trainer\u001B[38;5;241m.\u001B[39msave_model(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m./ner_model\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'trainer' is not defined"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T14:06:28.476786Z",
     "start_time": "2024-05-26T14:06:28.453239Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from transformers import BertTokenizerFast, BertForTokenClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Define the annotated training data\n",
    "train_data = [\n",
    "    {\n",
    "        \"text\": \"\"\"\n",
    "        Maria Elena Gonzalez\n",
    "        Location: San Francisco, CA | Phone: (415) 555-1234 | Email: maria.gonzalez@example.com\n",
    "        LinkedIn: https://www.linkedin.com/in/maria-elena-gonzalez/\n",
    "\n",
    "        Objective:\n",
    "        Detail-oriented Software Developer with a passion for creating innovative web applications. Seeking a position at Innovatech, where I can utilize my skills in front-end development, user experience design, and software engineering to contribute to the company's success.\n",
    "\n",
    "        Highlights of Qualifications:\n",
    "        - Extensive experience in developing responsive web applications using HTML, CSS, JavaScript, and React.\n",
    "        - Proficient in backend development with Node.js and Express.\n",
    "        - Skilled in using version control systems like Git and project management tools like Jira.\n",
    "        - Strong problem-solving abilities and a keen eye for detail.\n",
    "        - Excellent communication skills and a proven track record of collaborating effectively with cross-functional teams.\n",
    "\n",
    "        Technical Skills:\n",
    "        - Programming Languages: JavaScript, Python, Ruby\n",
    "        - Web Development: HTML, CSS, React, Angular, Node.js, Express\n",
    "        - Databases: MySQL, MongoDB, PostgreSQL\n",
    "        - Tools & Technologies: Docker, Kubernetes, Git, Jenkins, Jira\n",
    "        - Cloud Platforms: AWS, Heroku, Azure\n",
    "        - Other: Agile methodologies, Test-Driven Development (TDD), RESTful APIs\n",
    "\n",
    "        Education:\n",
    "        Bachelor of Science in Computer Science\n",
    "        University of California, San Francisco - San Francisco, CA\n",
    "        September 2015 - June 2019\n",
    "        - GPA: 3.8/4.0\n",
    "        - Relevant Coursework: Web Development, Data Structures, Algorithms, Database Systems, Cloud Computing\n",
    "\n",
    "        Professional Experience:\n",
    "        Front-End Developer\n",
    "        Web Creators Inc., San Francisco, CA\n",
    "        July 2019 - Present\n",
    "        - Developed and maintained front-end components for a high-traffic e-commerce platform using React and Redux.\n",
    "        - Improved site performance and user experience by optimizing CSS and JavaScript code.\n",
    "        - Collaborated with backend developers to integrate APIs and ensure seamless data flow.\n",
    "        - Participated in code reviews and provided mentorship to junior developers.\n",
    "\n",
    "        Software Developer Intern\n",
    "        Tech Innovators, Palo Alto, CA\n",
    "        June 2018 - August 2018\n",
    "        - Assisted in the development of a web-based project management tool using Angular and Node.js.\n",
    "        - Implemented RESTful APIs for data retrieval and storage.\n",
    "        - Conducted unit testing and debugging to ensure the reliability and performance of the application.\n",
    "\n",
    "        Research Assistant\n",
    "        Human-Computer Interaction Lab, UCSF\n",
    "        September 2017 - May 2018\n",
    "        - Conducted research on improving user interaction with web interfaces.\n",
    "        - Developed prototypes and conducted usability testing to gather user feedback.\n",
    "        - Published findings in a peer-reviewed journal and presented at the CHI Conference.\n",
    "\n",
    "        Projects:\n",
    "        Personal Portfolio Website\n",
    "        - Designed and developed a personal portfolio website to showcase my projects and skills.\n",
    "        - Used HTML, CSS, JavaScript, and React for the front-end and hosted on GitHub Pages.\n",
    "\n",
    "        E-commerce Website\n",
    "        - Developed a full-stack e-commerce website with user authentication, product listings, and a shopping cart.\n",
    "        - Used React for the front-end and Node.js with Express for the backend, with MongoDB as the database.\n",
    "\n",
    "        Certifications:\n",
    "        - Certified JavaScript Developer\n",
    "        - AWS Certified Developer - Associate\n",
    "        - Certified ScrumMaster (CSM)\n",
    "\n",
    "        Interests:\n",
    "        - Hiking, Photography, Traveling, Reading Tech Blogs, Volunteering at Coding Bootcamps, Playing the Piano\n",
    "        \"\"\",\n",
    "        \"labels\": [\n",
    "            (1, 22, \"NAME\"),            # Maria Elena Gonzalez\n",
    "            (62, 76, \"PHONE\"),          # (415) 555-1234\n",
    "            (85, 115, \"EMAIL\"),         # maria.gonzalez@example.com\n",
    "            (700, 710, \"SKILL\"),        # JavaScript\n",
    "            (712, 718, \"SKILL\"),        # Python\n",
    "            (720, 724, \"SKILL\"),        # Ruby\n",
    "            (747, 751, \"SKILL\"),        # HTML\n",
    "            (753, 756, \"SKILL\"),        # CSS\n",
    "            (758, 763, \"SKILL\"),        # React\n",
    "            (765, 772, \"SKILL\"),        # Angular\n",
    "            (774, 781, \"SKILL\"),        # Node.js\n",
    "            (783, 790, \"SKILL\"),        # Express\n",
    "            (813, 818, \"SKILL\"),        # MySQL\n",
    "            (820, 827, \"SKILL\"),        # MongoDB\n",
    "            (829, 838, \"SKILL\"),        # PostgreSQL\n",
    "            (860, 866, \"SKILL\"),        # Docker\n",
    "            (868, 878, \"SKILL\"),        # Kubernetes\n",
    "            (880, 883, \"SKILL\"),        # Git\n",
    "            (885, 892, \"SKILL\"),        # Jenkins\n",
    "            (894, 898, \"SKILL\"),        # Jira\n",
    "            (920, 923, \"SKILL\"),        # AWS\n",
    "            (925, 931, \"SKILL\"),        # Heroku\n",
    "            (933, 938, \"SKILL\"),        # Azure\n",
    "            (960, 978, \"SKILL\"),        # Agile methodologies\n",
    "            (980, 1004, \"SKILL\"),       # Test-Driven Development (TDD)\n",
    "            (1006, 1016, \"SKILL\"),      # RESTful APIs\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"\"\"\n",
    "        Lisa Marie Johnson\n",
    "        Location: Chicago, IL | Phone: (312) 555-6789 | Email: lisa.johnson@example.com\n",
    "        LinkedIn: https://www.linkedin.com/in/lisa-marie-johnson/\n",
    "\n",
    "        Objective:\n",
    "        Detail-oriented and highly organized Accountant with over 8 years of experience in financial reporting, budgeting, and auditing. Seeking a position at Financial Solutions Inc. to utilize my expertise in financial analysis, compliance, and team collaboration to support the company's financial health and growth.\n",
    "\n",
    "        Highlights of Qualifications:\n",
    "        - Extensive experience in preparing financial statements, balance sheets, and income statements.\n",
    "        - Proficient in conducting internal and external audits to ensure compliance with financial regulations and standards.\n",
    "        - Skilled in budgeting, forecasting, and financial planning.\n",
    "        - Strong analytical skills and attention to detail.\n",
    "        - Excellent communication skills and a proven track record of working effectively with cross-functional teams.\n",
    "\n",
    "        Technical Skills:\n",
    "        - Accounting Software: QuickBooks, SAP, Oracle Financials\n",
    "        - Financial Analysis Tools: Microsoft Excel, Microsoft Access, Tableau\n",
    "        - Regulatory Compliance: GAAP, IFRS, SOX\n",
    "        - Other: Financial Reporting, Budgeting, Auditing, Tax Preparation, Payroll Processing\n",
    "\n",
    "        Education:\n",
    "        Bachelor of Science in Accounting\n",
    "        University of Illinois at Chicago - Chicago, IL\n",
    "        September 2008 - June 2012\n",
    "        - GPA: 3.7/4.0\n",
    "        - Relevant Coursework: Financial Accounting, Managerial Accounting, Corporate Finance, Business Law\n",
    "\n",
    "        Professional Experience:\n",
    "        Senior Accountant\n",
    "        ABC Financial Services, Chicago, IL\n",
    "        July 2016 - Present\n",
    "        - Prepared and analyzed monthly, quarterly, and annual financial statements and reports.\n",
    "        - Conducted internal audits to ensure accuracy and compliance with GAAP and company policies.\n",
    "        - Managed budgeting and forecasting processes, collaborating with department heads to develop financial plans.\n",
    "        - Provided financial analysis and insights to support strategic decision-making.\n",
    "        - Supervised and mentored junior accounting staff.\n",
    "\n",
    "        Accountant\n",
    "        XYZ Corporation, Chicago, IL\n",
    "        June 2012 - June 2016\n",
    "        - Assisted in the preparation of financial statements and reports.\n",
    "        - Conducted variance analysis and reconciled accounts to ensure accuracy.\n",
    "        - Supported external audits by providing documentation and explanations of financial transactions.\n",
    "        - Processed payroll and prepared tax returns in compliance with federal and state regulations.\n",
    "        - Assisted in the implementation of a new accounting software system, improving efficiency and accuracy.\n",
    "\n",
    "        Projects:\n",
    "        Financial Reporting Automation\n",
    "        - Led a project to automate financial reporting processes using Microsoft Excel and VBA, reducing report generation time by 50%.\n",
    "\n",
    "        Budgeting and Forecasting Model\n",
    "        - Developed a comprehensive budgeting and forecasting model using Microsoft Access, improving accuracy and efficiency in financial planning.\n",
    "\n",
    "        Certifications:\n",
    "        - Certified Public Accountant (CPA)\n",
    "        - Certified Management Accountant (CMA)\n",
    "\n",
    "        Interests:\n",
    "        - Volunteering at Local Non-Profits, Reading Financial Journals, Traveling, Cooking, Yoga\n",
    "        \"\"\",\n",
    "        \"labels\": [\n",
    "            (1, 21, \"NAME\"),            # Lisa Marie Johnson\n",
    "            (51, 65, \"PHONE\"),          # (312) 555-6789\n",
    "            (74, 104, \"EMAIL\"),         # lisa.johnson@example.com\n",
    "            (665, 674, \"SKILL\"),        # QuickBooks\n",
    "            (676, 679, \"SKILL\"),        # SAP\n",
    "            (681, 699, \"SKILL\"),        # Oracle Financials\n",
    "            (723, 738, \"SKILL\"),        # Microsoft Excel\n",
    "            (740, 756, \"SKILL\"),        # Microsoft Access\n",
    "            (758, 765, \"SKILL\"),        # Tableau\n",
    "            (787, 791, \"SKILL\"),        # GAAP\n",
    "            (793, 797, \"SKILL\"),        # IFRS\n",
    "            (799, 802, \"SKILL\"),        # SOX\n",
    "            (824, 842, \"SKILL\"),        # Financial Reporting\n",
    "            (844, 853, \"SKILL\"),        # Budgeting\n",
    "            (855, 863, \"SKILL\"),        # Auditing\n",
    "            (865, 881, \"SKILL\"),        # Tax Preparation\n",
    "            (883, 900, \"SKILL\"),        # Payroll Processing\n",
    "        ]\n",
    "    },\n",
    "]"
   ],
   "id": "ab6bb3d71819a56a",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T14:06:29.832586Z",
     "start_time": "2024-05-26T14:06:29.737902Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a label mapping\n",
    "label_list = [\"O\", \"B-NAME\", \"I-NAME\", \"B-PHONE\", \"I-PHONE\", \"B-EMAIL\", \"I-EMAIL\", \"B-SKILL\", \"I-SKILL\"]\n",
    "label2id = {label: i for i, label in enumerate(label_list)}\n",
    "id2label = {i: label for i, label in enumerate(label_list)}\n",
    "\n",
    "# Use BertTokenizerFast\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"text\"], truncation=True, padding=True, return_offsets_mapping=True)\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[\"labels\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        label_ids = [-100] * len(tokenized_inputs[\"input_ids\"][i])\n",
    "        for start, end, entity in label:\n",
    "            start_idx = tokenized_inputs.char_to_token(i, start)\n",
    "            end_idx = tokenized_inputs.char_to_token(i, end - 1)\n",
    "            if start_idx is not None and end_idx is not None:\n",
    "                label_ids[start_idx:end_idx + 1] = [label2id[f\"B-{entity}\"]] + [label2id[f\"I-{entity}\"]] * (end_idx - start_idx)\n",
    "        labels.append(label_ids)\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n"
   ],
   "id": "64c02f880ae6bd1c",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T14:06:31.180514Z",
     "start_time": "2024-05-26T14:06:30.972298Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert the data to a Dataset\n",
    "train_dataset = Dataset.from_dict({\n",
    "    \"text\": [example[\"text\"] for example in train_data],\n",
    "    \"labels\": [example[\"labels\"] for example in train_data],\n",
    "})\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_and_align_labels, batched=True)\n"
   ],
   "id": "361a35c8e2d163cd",
   "outputs": [
    {
     "ename": "ArrowInvalid",
     "evalue": "Could not convert 'NAME' with type str: tried to convert to int64",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mArrowInvalid\u001B[0m                              Traceback (most recent call last)",
      "File \u001B[1;32mD:\\Developments\\Python\\DeepLearning\\NER_Resume\\.venv\\lib\\site-packages\\datasets\\arrow_writer.py:193\u001B[0m, in \u001B[0;36mTypedSequence.__arrow_array__\u001B[1;34m(self, type)\u001B[0m\n\u001B[0;32m    192\u001B[0m     trying_cast_to_python_objects \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m--> 193\u001B[0m     out \u001B[38;5;241m=\u001B[39m \u001B[43mpa\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43marray\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcast_to_python_objects\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43monly_1d_for_numpy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    194\u001B[0m \u001B[38;5;66;03m# use smaller integer precisions if possible\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Developments\\Python\\DeepLearning\\NER_Resume\\.venv\\lib\\site-packages\\pyarrow\\array.pxi:355\u001B[0m, in \u001B[0;36mpyarrow.lib.array\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mD:\\Developments\\Python\\DeepLearning\\NER_Resume\\.venv\\lib\\site-packages\\pyarrow\\array.pxi:42\u001B[0m, in \u001B[0;36mpyarrow.lib._sequence_to_array\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mD:\\Developments\\Python\\DeepLearning\\NER_Resume\\.venv\\lib\\site-packages\\pyarrow\\error.pxi:154\u001B[0m, in \u001B[0;36mpyarrow.lib.pyarrow_internal_check_status\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mD:\\Developments\\Python\\DeepLearning\\NER_Resume\\.venv\\lib\\site-packages\\pyarrow\\error.pxi:91\u001B[0m, in \u001B[0;36mpyarrow.lib.check_status\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mArrowInvalid\u001B[0m: Could not convert 'NAME' with type str: tried to convert to int64",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mArrowInvalid\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[20], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Convert the data to a Dataset\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m train_dataset \u001B[38;5;241m=\u001B[39m \u001B[43mDataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_dict\u001B[49m\u001B[43m(\u001B[49m\u001B[43m{\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtext\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43mexample\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtext\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mexample\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtrain_data\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlabels\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43mexample\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlabels\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mexample\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtrain_data\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      7\u001B[0m train_dataset \u001B[38;5;241m=\u001B[39m train_dataset\u001B[38;5;241m.\u001B[39mmap(tokenize_and_align_labels, batched\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[1;32mD:\\Developments\\Python\\DeepLearning\\NER_Resume\\.venv\\lib\\site-packages\\datasets\\arrow_dataset.py:963\u001B[0m, in \u001B[0;36mDataset.from_dict\u001B[1;34m(cls, mapping, features, info, split)\u001B[0m\n\u001B[0;32m    961\u001B[0m     arrow_typed_mapping[col] \u001B[38;5;241m=\u001B[39m data\n\u001B[0;32m    962\u001B[0m mapping \u001B[38;5;241m=\u001B[39m arrow_typed_mapping\n\u001B[1;32m--> 963\u001B[0m pa_table \u001B[38;5;241m=\u001B[39m \u001B[43mInMemoryTable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pydict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmapping\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmapping\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    964\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m info \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    965\u001B[0m     info \u001B[38;5;241m=\u001B[39m DatasetInfo()\n",
      "File \u001B[1;32mD:\\Developments\\Python\\DeepLearning\\NER_Resume\\.venv\\lib\\site-packages\\datasets\\table.py:758\u001B[0m, in \u001B[0;36mInMemoryTable.from_pydict\u001B[1;34m(cls, *args, **kwargs)\u001B[0m\n\u001B[0;32m    742\u001B[0m \u001B[38;5;129m@classmethod\u001B[39m\n\u001B[0;32m    743\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfrom_pydict\u001B[39m(\u001B[38;5;28mcls\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    744\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    745\u001B[0m \u001B[38;5;124;03m    Construct a Table from Arrow arrays or columns.\u001B[39;00m\n\u001B[0;32m    746\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    756\u001B[0m \u001B[38;5;124;03m        `datasets.table.Table`\u001B[39;00m\n\u001B[0;32m    757\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 758\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mcls\u001B[39m(pa\u001B[38;5;241m.\u001B[39mTable\u001B[38;5;241m.\u001B[39mfrom_pydict(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs))\n",
      "File \u001B[1;32mD:\\Developments\\Python\\DeepLearning\\NER_Resume\\.venv\\lib\\site-packages\\pyarrow\\table.pxi:1920\u001B[0m, in \u001B[0;36mpyarrow.lib._Tabular.from_pydict\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mD:\\Developments\\Python\\DeepLearning\\NER_Resume\\.venv\\lib\\site-packages\\pyarrow\\table.pxi:5992\u001B[0m, in \u001B[0;36mpyarrow.lib._from_pydict\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mD:\\Developments\\Python\\DeepLearning\\NER_Resume\\.venv\\lib\\site-packages\\pyarrow\\array.pxi:385\u001B[0m, in \u001B[0;36mpyarrow.lib.asarray\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mD:\\Developments\\Python\\DeepLearning\\NER_Resume\\.venv\\lib\\site-packages\\pyarrow\\array.pxi:247\u001B[0m, in \u001B[0;36mpyarrow.lib.array\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mD:\\Developments\\Python\\DeepLearning\\NER_Resume\\.venv\\lib\\site-packages\\pyarrow\\array.pxi:112\u001B[0m, in \u001B[0;36mpyarrow.lib._handle_arrow_array_protocol\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mD:\\Developments\\Python\\DeepLearning\\NER_Resume\\.venv\\lib\\site-packages\\datasets\\arrow_writer.py:261\u001B[0m, in \u001B[0;36mTypedSequence.__arrow_array__\u001B[1;34m(self, type)\u001B[0m\n\u001B[0;32m    259\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m out\n\u001B[0;32m    260\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m trying_cast_to_python_objects \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCould not convert\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(e):\n\u001B[1;32m--> 261\u001B[0m     out \u001B[38;5;241m=\u001B[39m \u001B[43mpa\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43marray\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcast_to_python_objects\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43monly_1d_for_numpy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimize_list_casting\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    262\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mtype\u001B[39m \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    263\u001B[0m         out \u001B[38;5;241m=\u001B[39m cast_array_to_feature(out, \u001B[38;5;28mtype\u001B[39m, allow_primitive_to_str\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, allow_decimal_to_str\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[1;32mD:\\Developments\\Python\\DeepLearning\\NER_Resume\\.venv\\lib\\site-packages\\pyarrow\\array.pxi:355\u001B[0m, in \u001B[0;36mpyarrow.lib.array\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mD:\\Developments\\Python\\DeepLearning\\NER_Resume\\.venv\\lib\\site-packages\\pyarrow\\array.pxi:42\u001B[0m, in \u001B[0;36mpyarrow.lib._sequence_to_array\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mD:\\Developments\\Python\\DeepLearning\\NER_Resume\\.venv\\lib\\site-packages\\pyarrow\\error.pxi:154\u001B[0m, in \u001B[0;36mpyarrow.lib.pyarrow_internal_check_status\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mD:\\Developments\\Python\\DeepLearning\\NER_Resume\\.venv\\lib\\site-packages\\pyarrow\\error.pxi:91\u001B[0m, in \u001B[0;36mpyarrow.lib.check_status\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mArrowInvalid\u001B[0m: Could not convert 'NAME' with type str: tried to convert to int64"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "# Define the model\n",
    "model = BertForTokenClassification.from_pretrained(\"bert-base-cased\", num_labels=len(set(entity for example in train_data for _, _, entity in example[\"labels\"])))\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "# Create Trainer instance\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()"
   ],
   "id": "c6bc43b6f550354d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
