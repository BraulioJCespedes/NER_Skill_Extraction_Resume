{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-27T22:57:12.840346Z",
     "start_time": "2024-05-27T22:57:06.060919Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForTokenClassification, Trainer, TrainingArguments\n",
    "from transformers import DataCollatorForTokenClassification\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T22:57:37.560503Z",
     "start_time": "2024-05-27T22:57:37.556497Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Sample resume\n",
    "resume_text = \"\"\"\n",
    "Johnathan Michael Smith\n",
    "Location: New York, NY | Phone: (212) 555-7890 | Email: johnathan.smith@example.com\n",
    "Skills:\n",
    "• Programming Languages: Java, Python, C++, JavaScript\n",
    "• Web Development: HTML, CSS, React, Node.js\n",
    "• Databases: PostgreSQL, MongoDB, MySQL\n",
    "• Tools & Technologies: Docker, Kubernetes, Git, Jenkins\n",
    "• Cloud Platforms: AWS, Azure, Google Cloud\n",
    "• Machine Learning: TensorFlow, PyTorch, scikit-learn\n",
    "• Other: Agile methodologies, Test-Driven Development, RESTful API design\n",
    "\"\"\""
   ],
   "id": "47afb7fecdc813f7",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T22:57:38.285191Z",
     "start_time": "2024-05-27T22:57:38.048310Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# Tokenize the resume\n",
    "tokens = tokenizer(resume_text, return_tensors=\"pt\", truncation=True, padding=True, is_split_into_words=True)\n"
   ],
   "id": "291b81d2d784946e",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T22:58:20.034114Z",
     "start_time": "2024-05-27T22:58:20.014596Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example tags (for demonstration purposes, actual tags need to be manually annotated)\n",
    "tags = [1] * len(tokens.input_ids[0])  # 0 for non-skill, 1 for skill (simplified)"
   ],
   "id": "d3e19ee3af974dc5",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T23:07:28.024065Z",
     "start_time": "2024-05-27T23:07:28.012550Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_actual_tags(resume_text):\n",
    "    tokens = tokenizer.tokenize(resume_text)\n",
    "    actual_tags = [0] * len(tokens)\n",
    "\n",
    "    # Example indices where skills are located (this should be based on your annotations)\n",
    "    skill_indices = [(5, 8), (10, 13)]  # Example: tokens 5-8 and 10-13 are skills\n",
    "\n",
    "    for start, end in skill_indices:\n",
    "        for i in range(start, end + 1):\n",
    "            actual_tags[i] = 1\n",
    "    \n",
    "    return actual_tags"
   ],
   "id": "9bda5efaf6c00f12",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T23:07:28.610889Z",
     "start_time": "2024-05-27T23:07:28.591327Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get actual tags for the test resume\n",
    "actual_tags = get_actual_tags(resume_text)"
   ],
   "id": "c027e90b7aa4716f",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T23:07:33.801424Z",
     "start_time": "2024-05-27T23:07:33.792914Z"
    }
   },
   "cell_type": "code",
   "source": "actual_tags",
   "id": "7d9174ca94b55284",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Convert tags to tensor\n",
    "tags_tensor = torch.tensor([tags])"
   ],
   "id": "8e33943b618cfc93",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Model\n",
    "model = BertForTokenClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "# Data collator\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)"
   ],
   "id": "baea6f789bf730da"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    ")"
   ],
   "id": "321ad4b4e953c68a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokens,\n",
    "    eval_dataset=tokens,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# Training\n",
    "trainer.train()"
   ],
   "id": "2481cc83ba45f223"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T23:21:17.104599Z",
     "start_time": "2024-05-27T23:21:16.937972Z"
    }
   },
   "cell_type": "code",
   "source": [
    "resume_text = \"\"\"\n",
    "Johnathan Michael Smith\n",
    "Location: New York, NY | Phone: (212) 555-7890 | Email: johnathan.smith@example.com\n",
    "\"\"\"\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# Tokenize the resume\n",
    "tokens = tokenizer.tokenize(resume_text)"
   ],
   "id": "c15112cbfbfc33b5",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T23:21:17.319272Z",
     "start_time": "2024-05-27T23:21:17.305756Z"
    }
   },
   "cell_type": "code",
   "source": "tokens",
   "id": "1c7ff79e11e5cd76",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['john',\n",
       " '##athan',\n",
       " 'michael',\n",
       " 'smith',\n",
       " 'location',\n",
       " ':',\n",
       " 'new',\n",
       " 'york',\n",
       " ',',\n",
       " 'ny',\n",
       " '|',\n",
       " 'phone',\n",
       " ':',\n",
       " '(',\n",
       " '212',\n",
       " ')',\n",
       " '555',\n",
       " '-',\n",
       " '78',\n",
       " '##90',\n",
       " '|',\n",
       " 'email',\n",
       " ':',\n",
       " 'john',\n",
       " '##athan',\n",
       " '.',\n",
       " 'smith',\n",
       " '@',\n",
       " 'example',\n",
       " '.',\n",
       " 'com']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "tags_list = [\n",
    "    \"B-NAME\",\n",
    "    \"I-NAME\",\n",
    "    \"B-PHONE\",\n",
    "    \"I-PHONE\",\n",
    "    \"B-EMAIL\",\n",
    "    \"B-SKILL\",\n",
    "    \"I-SKILL\"\n",
    "    \"O\"    \n",
    "]"
   ],
   "id": "5e7f0e4c432eaba8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
